{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aa3ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from dataset import GarbageClsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def pad_to_square(image: Image.Image, fill_color=(0, 0, 0)) -> Image.Image:\n",
    "    width, height = image.size\n",
    "    max_dim = max(width, height)\n",
    "    padded_image = ImageOps.pad(image, (max_dim, max_dim), color=fill_color, centering=(0.5, 0.5))\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d7e9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GarbageClsDataset('../data/annotations.csv', '../data/imgs/', transform = transforms.Compose([\n",
    "        pad_to_square, \n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62eb743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, _ = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3a8580e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76ee7ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media calcolata per canale (RGB): tensor([0.5581, 0.5410, 0.5185])\n",
      "Deviazione standard calcolata per canale (RGB): tensor([0.3177, 0.3070, 0.3034])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assicurati che il tuo dataset non abbia trasformazioni di normalizzazione applicate\n",
    "# in questa fase. Dovrebbe restituire tensori grezzi (es. 0-255 o 0-1).\n",
    "# Esempio: train_dataset = YourDataset(annotations_file, transform=transforms.ToTensor())\n",
    "\n",
    "# Usa un DataLoader per efficienza\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Inizializza le somme\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "n_images = 0\n",
    "\n",
    "# Itera sul DataLoader\n",
    "for images, _ in loader:\n",
    "    # Calcola la dimensione del batch\n",
    "    batch_samples = images.size(0)\n",
    "    # Riformatta le immagini per calcolare le statistiche per canale\n",
    "    # da (N, C, H, W) a (N, C, H*W)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    # Calcola la media per canale per il batch corrente e aggiorna la media totale\n",
    "    mean += images.mean(2).sum(0)\n",
    "    # Calcola la deviazione standard per canale per il batch corrente e aggiorna\n",
    "    std += images.std(2).sum(0)\n",
    "    # Aggiorna il conteggio totale delle immagini\n",
    "    n_images += batch_samples\n",
    "\n",
    "# Calcola la media e la deviazione standard finali\n",
    "mean /= n_images\n",
    "std /= n_images\n",
    "\n",
    "print(f\"Media calcolata per canale (RGB): {mean}\")\n",
    "print(f\"Deviazione standard calcolata per canale (RGB): {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2ec81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garbage_cls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
